\section{Algorithms}
Following classifiers are used in the assignment:  \textit{Logistic Regression}, \textit{Decision Tree}, \textit{$k-$Nearest Neighbor}, \textit{Support Vector Machine} and \textit{Neural Networks}. \textit{Logistic Regression} is applied in its Linear and Multinomial form. The algorithms are similar to the first assignment. The difference is that their classifier are used in platform. As well as mentioned classifiers, Principle Component Analysis (PCA) are used in the first dataset \ref{db:sec:ds1}. 

Since the major used algorithms were explained in the previous assignment, here is a brief description of new algorithms and techniques:

\begin{itemize}
\item \textbf{Logistic Regression :} Logistic regression can in many ways be seen to be similar to ordinary regression. However, the underlying principle of logistic regression, and its statistical calculation, are quite different to ordinary linear regression.  Logistic regression estimates the probability of an event occurring. It aims to predict the probability (p) that it is 1 (event occurring) rather than 0 (event not occurring) from a knowledge of relevant independent variables ~\cite{alg:logreg-def}. $C$ parameter in the classifier stands for Inverse of regularization strength which must be a positive float. Like in support vector machines, smaller values specify stronger regularization ~\cite{alg:logreg}.

\item \textbf{Principle Component Analysis (PCA):} Linear dimensionality reduction using Singular Value Decomposition of the data and keeping only the most significant singular vectors to project the data to a lower dimensional space  ~\cite{alg:pca}. It can be useful for reducing multi dimensional data into two or three dimensions in order to plot and understanding the distribution of data.
\end{itemize}
